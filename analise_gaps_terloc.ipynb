{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781419a6",
   "metadata": {},
   "source": [
    "# üìä An√°lise de Gaps Temporais - Troca de Notas TERLOC\n",
    "\n",
    "**Objetivo:** Medir gaps temporais no processo de troca de notas e identificar gargalos.\n",
    "\n",
    "## Gaps Principais a Medir:\n",
    "1. **Gap Cliente:** Retorno Simb√≥lico ‚Üí Recebimento NF Venda \n",
    "2. **Gap P√°tio:** Ticket ‚Üí Gate ‚Üí Libera√ß√£o\n",
    "3. **Processos Incompletos:** Linhas sem todos os hor√°rios\n",
    "\n",
    "## Processo TERLOC:\n",
    "Terminal ‚Üí Retorno Simb√≥lico ‚Üí Cliente emite NF Venda ‚Üí TERLOC recebe ‚Üí CEPARKING libera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0c6f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b381793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Abas encontradas: ['DADOS TERLOC', 'DADOS CEPARKING', 'Valida√ß√£o de dados', 'PLANILHA √öNICA', 'Legenda']\n",
      "\n",
      "üéØ CARREGANDO ABA 'PLANILHA √öNICA' COM DADOS OPERACIONAIS...\n",
      "‚úÖ Dados operacionais carregados: 1,045,190 registros\n",
      "üîç Colunas dispon√≠veis: 179 colunas\n",
      "üéØ Colunas importantes identificadas: ['DATA', 'EXPEDI√á√ÉO', 'MOTORISTA', 'CLIENTE', 'CLIENTE DE VENDA', 'DATA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA RECEBIMENTO NF DE VENDA', 'DATA  TICKET', 'HORA TICKET', 'HORARIO SENHA ', 'HORA GATE ', 'DATA DE LIBERA√á√ÉO', 'HORARIO DE LIBERA√á√ÉO']\n",
      "‚úÖ Dados operacionais carregados: 1,045,190 registros\n",
      "üîç Colunas dispon√≠veis: 179 colunas\n",
      "üéØ Colunas importantes identificadas: ['DATA', 'EXPEDI√á√ÉO', 'MOTORISTA', 'CLIENTE', 'CLIENTE DE VENDA', 'DATA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA RECEBIMENTO NF DE VENDA', 'DATA  TICKET', 'HORA TICKET', 'HORARIO SENHA ', 'HORA GATE ', 'DATA DE LIBERA√á√ÉO', 'HORARIO DE LIBERA√á√ÉO']\n"
     ]
    }
   ],
   "source": [
    "# Carregar planilha TERLOC - ABA CORRETA COM DADOS OPERACIONAIS\n",
    "arquivo_excel = 'PLANILHA TROCA DE NOTA TERLOC.xlsx'\n",
    "\n",
    "try:\n",
    "    # Tentar carregar todas as abas\n",
    "    excel_file = pd.ExcelFile(arquivo_excel)\n",
    "    print(f\"üìã Abas encontradas: {excel_file.sheet_names}\")\n",
    "    \n",
    "    # ‚ö†Ô∏è CARREGAR ABA 'PLANILHA √öNICA' - DADOS OPERACIONAIS COMPLETOS\n",
    "    print(f\"\\nüéØ CARREGANDO ABA 'PLANILHA √öNICA' COM DADOS OPERACIONAIS...\")\n",
    "    df = pd.read_excel(arquivo_excel, sheet_name='PLANILHA √öNICA')\n",
    "    print(f\"‚úÖ Dados operacionais carregados: {len(df):,} registros\")\n",
    "    print(f\"üîç Colunas dispon√≠veis: {len(df.columns)} colunas\")\n",
    "    \n",
    "    # Mostrar primeiras colunas importantes\n",
    "    colunas_importantes = []\n",
    "    for col in df.columns[:20]:  # Primeiras 20 colunas\n",
    "        if any(palavra in str(col).lower() for palavra in ['data', 'hora', 'cliente', 'expedi√ß√£o', 'motorista']):\n",
    "            colunas_importantes.append(col)\n",
    "    \n",
    "    print(f\"üéØ Colunas importantes identificadas: {colunas_importantes}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao carregar planilha: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6928e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ANALISANDO TODAS AS ABAS DA PLANILHA:\n",
      "\n",
      "üìã ABA 1: 'DADOS TERLOC'\n",
      "   üìä Linhas: 77\n",
      "   üìã Colunas: 4\n",
      "   üìù Nomes das colunas: ['TERLOC', 'E-MAIL', 'Unnamed: 2', 'Unnamed: 3']...\n",
      "   ‚ùå Nenhuma coluna de tempo encontrada\n",
      "\n",
      "üìã ABA 2: 'DADOS CEPARKING'\n",
      "   üìä Linhas: 59\n",
      "   üìã Colunas: 3\n",
      "   üìù Nomes das colunas: ['CEPARKING', 'Unnamed: 1', 'Unnamed: 2']...\n",
      "   ‚ùå Nenhuma coluna de tempo encontrada\n",
      "\n",
      "üìã ABA 3: 'Valida√ß√£o de dados'\n",
      "   üìä Linhas: 20\n",
      "   üìã Colunas: 3\n",
      "   üìù Nomes das colunas: ['CLIENTES VENDA', 'Unnamed: 1', 'CLIENTES DE ORIGEM']...\n",
      "   ‚ùå Nenhuma coluna de tempo encontrada\n",
      "\n",
      "üìã ABA 4: 'PLANILHA √öNICA'\n",
      "   üìä Linhas: 1045190\n",
      "   üìã Colunas: 179\n",
      "   üìù Nomes das colunas: ['DATA', 'EXPEDI√á√ÉO', 'MOTORISTA', 'PLACA', 'CLIENTE', 'CLIENTE DE VENDA', 'POSSUI NF DE CONTA E ORDEM?', 'DATA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA  EMISS√ÉO RETORNO SIMB√ìLICO', 'RETORNO SIMB√ìLICO ']...\n",
      "   ‚è∞ COLUNAS DE TEMPO ENCONTRADAS: ['DATA', 'DATA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA  EMISS√ÉO RETORNO SIMB√ìLICO', 'RETORNO SIMB√ìLICO ', 'HORA RECEBIMENTO NF DE VENDA', 'DATA  TICKET', 'HORA TICKET', 'HORARIO SENHA ', 'HORA GATE ', 'DATA DE LIBERA√á√ÉO', 'HORARIO DE LIBERA√á√ÉO', 'COLABORADOR LIBERA√á√ÉO']\n",
      "\n",
      "üìã ABA 5: 'Legenda'\n",
      "   üìä Linhas: 5\n",
      "   üìã Colunas: 4\n",
      "   üìù Nomes das colunas: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']...\n",
      "   ‚ùå Nenhuma coluna de tempo encontrada\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar todas as abas da planilha para encontrar os dados corretos\n",
    "print(\"üîç ANALISANDO TODAS AS ABAS DA PLANILHA:\")\n",
    "\n",
    "for i, aba in enumerate(excel_file.sheet_names):\n",
    "    print(f\"\\nüìã ABA {i+1}: '{aba}'\")\n",
    "    try:\n",
    "        df_temp = pd.read_excel(arquivo_excel, sheet_name=aba)\n",
    "        print(f\"   üìä Linhas: {len(df_temp)}\")\n",
    "        print(f\"   üìã Colunas: {len(df_temp.columns)}\")\n",
    "        print(f\"   üìù Nomes das colunas: {list(df_temp.columns)[:10]}...\")  # Primeiras 10 colunas\n",
    "        \n",
    "        # Verificar se tem colunas de tempo\n",
    "        colunas_tempo = []\n",
    "        for col in df_temp.columns:\n",
    "            col_lower = str(col).lower()\n",
    "            if any(palavra in col_lower for palavra in ['data', 'hora', 'ticket', 'gate', 'libera√ß√£o', 'retorno']):\n",
    "                colunas_tempo.append(col)\n",
    "        \n",
    "        if colunas_tempo:\n",
    "            print(f\"   ‚è∞ COLUNAS DE TEMPO ENCONTRADAS: {colunas_tempo}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Nenhuma coluna de tempo encontrada\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro ao ler aba: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar estrutura dos dados operacionais REAIS\n",
    "print(\"üìã ESTRUTURA DOS DADOS OPERACIONAIS:\")\n",
    "print(f\"üìä Total de Registros: {len(df):,}\")\n",
    "print(f\"üìã Total de Colunas: {len(df.columns)}\")\n",
    "\n",
    "# Verificar dados dos √∫ltimos meses (dados mais recentes)\n",
    "print(f\"\\nüîç ANALISANDO DADOS RECENTES:\")\n",
    "df_recente = df[df['DATA'].notna()].copy()\n",
    "if len(df_recente) > 0:\n",
    "    df_recente['DATA'] = pd.to_datetime(df_recente['DATA'], errors='coerce')\n",
    "    df_recente = df_recente[df_recente['DATA'].notna()]\n",
    "    \n",
    "    if len(df_recente) > 0:\n",
    "        data_min = df_recente['DATA'].min()\n",
    "        data_max = df_recente['DATA'].max()\n",
    "        print(f\"üìÖ Per√≠odo dos dados: {data_min.date()} at√© {data_max.date()}\")\n",
    "        \n",
    "        # Filtrar √∫ltimos 30 dias para an√°lise\n",
    "        from datetime import datetime, timedelta\n",
    "        data_corte = data_max - timedelta(days=30)\n",
    "        df_ultimos_30 = df_recente[df_recente['DATA'] >= data_corte]\n",
    "        print(f\"üìä Registros √∫ltimos 30 dias: {len(df_ultimos_30):,}\")\n",
    "\n",
    "print(f\"\\nüéØ COLUNAS CR√çTICAS PARA AN√ÅLISE DE GAPS:\")\n",
    "colunas_gaps = ['DATA', 'EXPEDI√á√ÉO', 'MOTORISTA', 'CLIENTE', 'CLIENTE DE VENDA', \n",
    "                'DATA  EMISS√ÉO RETORNO SIMB√ìLICO', 'HORA  EMISS√ÉO RETORNO SIMB√ìLICO',\n",
    "                'HORA RECEBIMENTO NF DE VENDA', 'DATA  TICKET', 'HORA TICKET',\n",
    "                'HORARIO SENHA ', 'HORA GATE ', 'DATA DE LIBERA√á√ÉO', 'HORARIO DE LIBERA√á√ÉO']\n",
    "\n",
    "for col in colunas_gaps:\n",
    "    if col in df.columns:\n",
    "        valores_preenchidos = df[col].notna().sum()\n",
    "        percentual = (valores_preenchidos / len(df)) * 100\n",
    "        status = \"‚úÖ\" if percentual > 50 else \"‚ö†Ô∏è\" if percentual > 10 else \"‚ùå\"\n",
    "        print(f\"{status} {col}: {valores_preenchidos:,} valores ({percentual:.1f}%)\")\n",
    "\n",
    "# Mostrar amostra dos dados\n",
    "print(f\"\\n\udd0d AMOSTRA DOS DADOS (primeiras 3 linhas):\")\n",
    "display(df[colunas_gaps].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f034689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para combinar data e hora em datetime\n",
    "def combinar_data_hora(df, col_data, col_hora):\n",
    "    \"\"\"\n",
    "    Combina colunas de data e hora em um datetime √∫nico\n",
    "    \"\"\"\n",
    "    resultado = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            data = df.iloc[i][col_data]\n",
    "            hora = df.iloc[i][col_hora]\n",
    "            \n",
    "            # Verificar se ambos existem\n",
    "            if pd.notna(data) and pd.notna(hora):\n",
    "                # Converter data para datetime se necess√°rio\n",
    "                if isinstance(data, str):\n",
    "                    data = pd.to_datetime(data, errors='coerce')\n",
    "                \n",
    "                # Combinar data e hora\n",
    "                if isinstance(hora, str):\n",
    "                    # Tentar converter string de hora\n",
    "                    try:\n",
    "                        hora_dt = pd.to_datetime(hora, format='%H:%M', errors='coerce').time()\n",
    "                        datetime_completo = pd.Timestamp.combine(data.date(), hora_dt)\n",
    "                    except:\n",
    "                        datetime_completo = pd.NaT\n",
    "                else:\n",
    "                    datetime_completo = data\n",
    "                \n",
    "                resultado.append(datetime_completo)\n",
    "            else:\n",
    "                resultado.append(pd.NaT)\n",
    "                \n",
    "        except Exception as e:\n",
    "            resultado.append(pd.NaT)\n",
    "    \n",
    "    return pd.Series(resultado)\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de combina√ß√£o data/hora criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05008254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar e combinar colunas de data/hora\n",
    "colunas = df.columns.tolist()\n",
    "print(\"üîç MAPEAMENTO DAS COLUNAS DE TEMPO:\")\n",
    "\n",
    "# Mapear colunas esperadas\n",
    "mapa_colunas = {\n",
    "    'data_carregamento': None,\n",
    "    'data_retorno_simbolico': None,\n",
    "    'hora_retorno_simbolico': None,\n",
    "    'hora_recebimento_nf': None,\n",
    "    'data_ticket': None,\n",
    "    'hora_ticket': None,\n",
    "    'hora_senha': None,\n",
    "    'hora_gate': None,\n",
    "    'data_liberacao': None,\n",
    "    'hora_liberacao': None\n",
    "}\n",
    "\n",
    "# Identificar colunas automaticamente\n",
    "for col in colunas:\n",
    "    col_lower = col.lower()\n",
    "    \n",
    "    if 'data' in col_lower and 'carregamento' in col_lower:\n",
    "        mapa_colunas['data_carregamento'] = col\n",
    "    elif 'data' in col_lower and 'retorno' in col_lower:\n",
    "        mapa_colunas['data_retorno_simbolico'] = col\n",
    "    elif 'hora' in col_lower and 'retorno' in col_lower:\n",
    "        mapa_colunas['hora_retorno_simbolico'] = col\n",
    "    elif 'hora' in col_lower and 'recebimento' in col_lower:\n",
    "        mapa_colunas['hora_recebimento_nf'] = col\n",
    "    elif 'data' in col_lower and 'ticket' in col_lower:\n",
    "        mapa_colunas['data_ticket'] = col\n",
    "    elif 'hora' in col_lower and 'ticket' in col_lower:\n",
    "        mapa_colunas['hora_ticket'] = col\n",
    "    elif 'hora' in col_lower and 'senha' in col_lower:\n",
    "        mapa_colunas['hora_senha'] = col\n",
    "    elif 'hora' in col_lower and 'gate' in col_lower:\n",
    "        mapa_colunas['hora_gate'] = col\n",
    "    elif 'data' in col_lower and 'libera√ß√£o' in col_lower:\n",
    "        mapa_colunas['data_liberacao'] = col\n",
    "    elif 'hora' in col_lower and 'libera√ß√£o' in col_lower:\n",
    "        mapa_colunas['hora_liberacao'] = col\n",
    "\n",
    "# Exibir mapeamento\n",
    "for chave, valor in mapa_colunas.items():\n",
    "    status = \"‚úÖ\" if valor else \"‚ùå\"\n",
    "    print(f\"{status} {chave}: {valor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar timestamps combinados para an√°lise\n",
    "print(\"üîÑ CRIANDO TIMESTAMPS COMBINADOS...\")\n",
    "\n",
    "# C√≥pia do dataframe para trabalhar\n",
    "df_analise = df.copy()\n",
    "\n",
    "# Criar timestamps combinados onde poss√≠vel\n",
    "if mapa_colunas['data_retorno_simbolico'] and mapa_colunas['hora_retorno_simbolico']:\n",
    "    df_analise['timestamp_retorno_simbolico'] = combinar_data_hora(\n",
    "        df_analise, \n",
    "        mapa_colunas['data_retorno_simbolico'], \n",
    "        mapa_colunas['hora_retorno_simbolico']\n",
    "    )\n",
    "    print(\"‚úÖ Timestamp retorno simb√≥lico criado\")\n",
    "\n",
    "if mapa_colunas['hora_recebimento_nf']:\n",
    "    # Assumindo que usa a mesma data do retorno simb√≥lico se n√£o houver data espec√≠fica\n",
    "    df_analise['timestamp_recebimento_nf'] = pd.to_datetime(\n",
    "        df_analise[mapa_colunas['hora_recebimento_nf']], errors='coerce'\n",
    "    )\n",
    "    print(\"‚úÖ Timestamp recebimento NF criado\")\n",
    "\n",
    "if mapa_colunas['data_ticket'] and mapa_colunas['hora_ticket']:\n",
    "    df_analise['timestamp_ticket'] = combinar_data_hora(\n",
    "        df_analise, \n",
    "        mapa_colunas['data_ticket'], \n",
    "        mapa_colunas['hora_ticket']\n",
    "    )\n",
    "    print(\"‚úÖ Timestamp ticket criado\")\n",
    "\n",
    "if mapa_colunas['hora_gate']:\n",
    "    df_analise['timestamp_gate'] = pd.to_datetime(\n",
    "        df_analise[mapa_colunas['hora_gate']], errors='coerce'\n",
    "    )\n",
    "    print(\"‚úÖ Timestamp gate criado\")\n",
    "\n",
    "if mapa_colunas['data_liberacao'] and mapa_colunas['hora_liberacao']:\n",
    "    df_analise['timestamp_liberacao'] = combinar_data_hora(\n",
    "        df_analise, \n",
    "        mapa_colunas['data_liberacao'], \n",
    "        mapa_colunas['hora_liberacao']\n",
    "    )\n",
    "    print(\"‚úÖ Timestamp libera√ß√£o criado\")\n",
    "\n",
    "print(f\"\\nüìä DataFrame de an√°lise criado com {len(df_analise)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54588d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE 1: CALCULAR GAPS TEMPORAIS\n",
    "print(\"‚è±Ô∏è CALCULANDO GAPS TEMPORAIS...\")\n",
    "\n",
    "# Gap Cliente: Retorno Simb√≥lico ‚Üí Recebimento NF Venda\n",
    "if 'timestamp_retorno_simbolico' in df_analise.columns and 'timestamp_recebimento_nf' in df_analise.columns:\n",
    "    df_analise['gap_cliente_horas'] = (\n",
    "        df_analise['timestamp_recebimento_nf'] - df_analise['timestamp_retorno_simbolico']\n",
    "    ).dt.total_seconds() / 3600\n",
    "    print(\"‚úÖ Gap Cliente calculado (horas)\")\n",
    "\n",
    "# Gap P√°tio: Ticket ‚Üí Libera√ß√£o  \n",
    "if 'timestamp_ticket' in df_analise.columns and 'timestamp_liberacao' in df_analise.columns:\n",
    "    df_analise['gap_patio_horas'] = (\n",
    "        df_analise['timestamp_liberacao'] - df_analise['timestamp_ticket']\n",
    "    ).dt.total_seconds() / 3600\n",
    "    print(\"‚úÖ Gap P√°tio calculado (horas)\")\n",
    "\n",
    "# Gap Gate: Ticket ‚Üí Gate\n",
    "if 'timestamp_ticket' in df_analise.columns and 'timestamp_gate' in df_analise.columns:\n",
    "    df_analise['gap_ticket_gate_horas'] = (\n",
    "        df_analise['timestamp_gate'] - df_analise['timestamp_ticket']\n",
    "    ).dt.total_seconds() / 3600\n",
    "    print(\"‚úÖ Gap Ticket‚ÜíGate calculado (horas)\")\n",
    "\n",
    "# Gap Libera√ß√£o: Gate ‚Üí Libera√ß√£o\n",
    "if 'timestamp_gate' in df_analise.columns and 'timestamp_liberacao' in df_analise.columns:\n",
    "    df_analise['gap_gate_liberacao_horas'] = (\n",
    "        df_analise['timestamp_liberacao'] - df_analise['timestamp_gate']\n",
    "    ).dt.total_seconds() / 3600\n",
    "    print(\"‚úÖ Gap Gate‚ÜíLibera√ß√£o calculado (horas)\")\n",
    "\n",
    "print(\"\\nüìà GAPS CALCULADOS COM SUCESSO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f41867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE 2: IDENTIFICAR PROCESSOS INCOMPLETOS\n",
    "print(\"üîç IDENTIFICANDO PROCESSOS INCOMPLETOS...\")\n",
    "\n",
    "# Definir campos cr√≠ticos para processo completo\n",
    "campos_criticos = []\n",
    "if 'timestamp_retorno_simbolico' in df_analise.columns:\n",
    "    campos_criticos.append('timestamp_retorno_simbolico')\n",
    "if 'timestamp_recebimento_nf' in df_analise.columns:\n",
    "    campos_criticos.append('timestamp_recebimento_nf')\n",
    "if 'timestamp_ticket' in df_analise.columns:\n",
    "    campos_criticos.append('timestamp_ticket')\n",
    "if 'timestamp_liberacao' in df_analise.columns:\n",
    "    campos_criticos.append('timestamp_liberacao')\n",
    "\n",
    "# Identificar processos incompletos\n",
    "df_analise['processo_completo'] = True\n",
    "df_analise['campos_faltantes'] = ''\n",
    "\n",
    "for i, row in df_analise.iterrows():\n",
    "    faltantes = []\n",
    "    for campo in campos_criticos:\n",
    "        if pd.isna(row[campo]):\n",
    "            faltantes.append(campo.replace('timestamp_', ''))\n",
    "    \n",
    "    if faltantes:\n",
    "        df_analise.loc[i, 'processo_completo'] = False\n",
    "        df_analise.loc[i, 'campos_faltantes'] = ', '.join(faltantes)\n",
    "\n",
    "# Estat√≠sticas de completude\n",
    "total_processos = len(df_analise)\n",
    "processos_completos = df_analise['processo_completo'].sum()\n",
    "processos_incompletos = total_processos - processos_completos\n",
    "\n",
    "print(f\"üìä ESTAT√çSTICAS DE COMPLETUDE:\")\n",
    "print(f\"‚úÖ Processos Completos: {processos_completos} ({processos_completos/total_processos*100:.1f}%)\")\n",
    "print(f\"‚ùå Processos Incompletos: {processos_incompletos} ({processos_incompletos/total_processos*100:.1f}%)\")\n",
    "print(f\"üìã Total: {total_processos}\")\n",
    "\n",
    "if processos_incompletos > 0:\n",
    "    print(f\"\\nüîç CAMPOS MAIS FALTANTES:\")\n",
    "    campos_faltantes = df_analise[df_analise['processo_completo'] == False]['campos_faltantes'].str.split(', ').explode()\n",
    "    contagem_faltantes = campos_faltantes.value_counts()\n",
    "    print(contagem_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE 3: ESTAT√çSTICAS DOS GAPS\n",
    "print(\"üìà ESTAT√çSTICAS DOS GAPS TEMPORAIS:\")\n",
    "\n",
    "# Filtrar apenas processos com gaps v√°lidos\n",
    "df_completos = df_analise[df_analise['processo_completo'] == True]\n",
    "\n",
    "gaps_para_analisar = []\n",
    "if 'gap_cliente_horas' in df_analise.columns:\n",
    "    gaps_para_analisar.append(('Gap Cliente (Retorno‚ÜíNF)', 'gap_cliente_horas'))\n",
    "if 'gap_patio_horas' in df_analise.columns:\n",
    "    gaps_para_analisar.append(('Gap P√°tio (Ticket‚ÜíLibera√ß√£o)', 'gap_patio_horas'))\n",
    "if 'gap_ticket_gate_horas' in df_analise.columns:\n",
    "    gaps_para_analisar.append(('Gap Ticket‚ÜíGate', 'gap_ticket_gate_horas'))\n",
    "if 'gap_gate_liberacao_horas' in df_analise.columns:\n",
    "    gaps_para_analisar.append(('Gap Gate‚ÜíLibera√ß√£o', 'gap_gate_liberacao_horas'))\n",
    "\n",
    "for nome_gap, coluna_gap in gaps_para_analisar:\n",
    "    dados_validos = df_completos[coluna_gap].dropna()\n",
    "    if len(dados_validos) > 0:\n",
    "        print(f\"\\n‚è±Ô∏è {nome_gap}:\")\n",
    "        print(f\"   üìä M√©dia: {dados_validos.mean():.1f} horas\")\n",
    "        print(f\"   üìä Mediana: {dados_validos.median():.1f} horas\")\n",
    "        print(f\"   üìä M√≠nimo: {dados_validos.min():.1f} horas\")\n",
    "        print(f\"   üìä M√°ximo: {dados_validos.max():.1f} horas\")\n",
    "        print(f\"   üìä Desvio Padr√£o: {dados_validos.std():.1f} horas\")\n",
    "        print(f\"   üìä Casos v√°lidos: {len(dados_validos)}\")\n",
    "        \n",
    "        # Identificar casos extremos (gaps > 24h)\n",
    "        extremos = dados_validos[dados_validos > 24]\n",
    "        if len(extremos) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è Casos > 24h: {len(extremos)} ({len(extremos)/len(dados_validos)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba57fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASHBOARD 1: VIS√ÉO GERAL DE PROCESSOS\n",
    "print(\"üìä CRIANDO DASHBOARD DE VIS√ÉO GERAL...\")\n",
    "\n",
    "# Gr√°fico de pizza - Processos Completos vs Incompletos\n",
    "fig_completude = go.Figure(data=[go.Pie(\n",
    "    labels=['Processos Completos', 'Processos Incompletos'],\n",
    "    values=[processos_completos, processos_incompletos],\n",
    "    hole=.3,\n",
    "    marker_colors=['#2E8B57', '#DC143C']\n",
    ")])\n",
    "\n",
    "fig_completude.update_layout(\n",
    "    title={\n",
    "        'text': f'üìã Completude dos Processos (Total: {total_processos})',\n",
    "        'x': 0.5,\n",
    "        'font': {'size': 16}\n",
    "    },\n",
    "    showlegend=True,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig_completude.show()\n",
    "\n",
    "# M√©tricas principais\n",
    "print(f\"\\nüéØ M√âTRICAS PRINCIPAIS:\")\n",
    "print(f\"üìã Total de Processos: {total_processos}\")\n",
    "print(f\"‚úÖ Taxa de Completude: {processos_completos/total_processos*100:.1f}%\")\n",
    "print(f\"‚ùå Processos Incompletos: {processos_incompletos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASHBOARD 2: AN√ÅLISE DE GAPS TEMPORAIS\n",
    "print(\"üìà CRIANDO DASHBOARD DE GAPS TEMPORAIS...\")\n",
    "\n",
    "if gaps_para_analisar:\n",
    "    # Criar subplots para histogramas dos gaps\n",
    "    n_gaps = len(gaps_para_analisar)\n",
    "    fig_gaps = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[nome for nome, _ in gaps_para_analisar[:4]],\n",
    "        vertical_spacing=0.12\n",
    "    )\n",
    "    \n",
    "    posicoes = [(1,1), (1,2), (2,1), (2,2)]\n",
    "    \n",
    "    for i, (nome_gap, coluna_gap) in enumerate(gaps_para_analisar[:4]):\n",
    "        dados_validos = df_completos[coluna_gap].dropna()\n",
    "        if len(dados_validos) > 0:\n",
    "            # Filtrar outliers extremos para melhor visualiza√ß√£o\n",
    "            q95 = dados_validos.quantile(0.95)\n",
    "            dados_filtrados = dados_validos[dados_validos <= q95]\n",
    "            \n",
    "            fig_gaps.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=dados_filtrados,\n",
    "                    nbinsx=20,\n",
    "                    name=nome_gap,\n",
    "                    marker_color='#1f77b4',\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                row=posicoes[i][0], col=posicoes[i][1]\n",
    "            )\n",
    "            \n",
    "            # Adicionar linha da m√©dia\n",
    "            media = dados_validos.mean()\n",
    "            fig_gaps.add_vline(\n",
    "                x=media, line_dash=\"dash\", line_color=\"red\",\n",
    "                annotation_text=f\"M√©dia: {media:.1f}h\",\n",
    "                row=posicoes[i][0], col=posicoes[i][1]\n",
    "            )\n",
    "    \n",
    "    fig_gaps.update_layout(\n",
    "        title_text=\"‚è±Ô∏è Distribui√ß√£o dos Gaps Temporais (horas)\",\n",
    "        showlegend=False,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig_gaps.update_xaxes(title_text=\"Horas\")\n",
    "    fig_gaps.update_yaxes(title_text=\"Frequ√™ncia\")\n",
    "    \n",
    "    fig_gaps.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel criar gr√°ficos de gaps - dados insuficientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASHBOARD 3: LINHA DO TEMPO DE PROCESSOS SELECIONADOS\n",
    "print(\"üïê CRIANDO LINHA DO TEMPO DOS PROCESSOS...\")\n",
    "\n",
    "# Selecionar processos completos para linha do tempo\n",
    "df_timeline = df_completos.head(10)  # Primeiros 10 processos completos\n",
    "\n",
    "if len(df_timeline) > 0:\n",
    "    fig_timeline = go.Figure()\n",
    "    \n",
    "    # Definir eventos e cores\n",
    "    eventos = []\n",
    "    cores = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n",
    "    \n",
    "    if 'timestamp_retorno_simbolico' in df_timeline.columns:\n",
    "        eventos.append(('Retorno Simb√≥lico', 'timestamp_retorno_simbolico', cores[0]))\n",
    "    if 'timestamp_recebimento_nf' in df_timeline.columns:\n",
    "        eventos.append(('Recebimento NF', 'timestamp_recebimento_nf', cores[1]))\n",
    "    if 'timestamp_ticket' in df_timeline.columns:\n",
    "        eventos.append(('Ticket', 'timestamp_ticket', cores[2]))\n",
    "    if 'timestamp_gate' in df_timeline.columns:\n",
    "        eventos.append(('Gate', 'timestamp_gate', cores[3]))\n",
    "    if 'timestamp_liberacao' in df_timeline.columns:\n",
    "        eventos.append(('Libera√ß√£o', 'timestamp_liberacao', cores[4]))\n",
    "    \n",
    "    # Adicionar pontos para cada evento\n",
    "    for nome_evento, coluna_evento, cor in eventos:\n",
    "        dados_validos = df_timeline[coluna_evento].dropna()\n",
    "        indices = dados_validos.index\n",
    "        \n",
    "        fig_timeline.add_trace(go.Scatter(\n",
    "            x=dados_validos,\n",
    "            y=[f\"Processo {i}\" for i in indices],\n",
    "            mode='markers',\n",
    "            name=nome_evento,\n",
    "            marker=dict(size=10, color=cor),\n",
    "            text=[f\"{nome_evento}<br>Processo {i}\" for i in indices],\n",
    "            hovertemplate='%{text}<br>%{x}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    fig_timeline.update_layout(\n",
    "        title=\"üïê Linha do Tempo dos Processos (Primeiros 10 Completos)\",\n",
    "        xaxis_title=\"Data/Hora\",\n",
    "        yaxis_title=\"Processos\",\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_timeline.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå N√£o h√° processos completos suficientes para criar linha do tempo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e683e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELAT√ìRIO EXECUTIVO PARA O GERENTE\n",
    "print(\"üìã RELAT√ìRIO EXECUTIVO - GAPS TERLOC\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüéØ RESUMO GERAL:\")\n",
    "print(f\"   üìä Total de Processos Analisados: {total_processos}\")\n",
    "print(f\"   ‚úÖ Processos Completos: {processos_completos} ({processos_completos/total_processos*100:.1f}%)\")\n",
    "print(f\"   ‚ùå Processos Incompletos: {processos_incompletos} ({processos_incompletos/total_processos*100:.1f}%)\")\n",
    "\n",
    "if gaps_para_analisar:\n",
    "    print(f\"\\n‚è±Ô∏è GAPS TEMPORAIS PRINCIPAIS:\")\n",
    "    for nome_gap, coluna_gap in gaps_para_analisar:\n",
    "        dados_validos = df_completos[coluna_gap].dropna()\n",
    "        if len(dados_validos) > 0:\n",
    "            media = dados_validos.mean()\n",
    "            casos_24h = len(dados_validos[dados_validos > 24])\n",
    "            print(f\"   üìà {nome_gap}:\")\n",
    "            print(f\"      ‚Ä¢ Tempo M√©dio: {media:.1f} horas\")\n",
    "            print(f\"      ‚Ä¢ Casos > 24h: {casos_24h} ({casos_24h/len(dados_validos)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüö® ALERTAS E RECOMENDA√á√ïES:\")\n",
    "if processos_incompletos > total_processos * 0.3:\n",
    "    print(f\"   ‚ö†Ô∏è ALTA taxa de processos incompletos ({processos_incompletos/total_processos*100:.1f}%)\")\n",
    "    print(f\"   üí° Revisar processos de coleta de dados e follow-up\")\n",
    "\n",
    "if 'gap_cliente_horas' in df_analise.columns:\n",
    "    gap_cliente_dados = df_completos['gap_cliente_horas'].dropna()\n",
    "    if len(gap_cliente_dados) > 0 and gap_cliente_dados.mean() > 12:\n",
    "        print(f\"   ‚ö†Ô∏è Gap Cliente muito alto (m√©dia: {gap_cliente_dados.mean():.1f}h)\")\n",
    "        print(f\"   üí° Melhorar comunica√ß√£o com clientes sobre prazos de NF\")\n",
    "\n",
    "if 'gap_patio_horas' in df_analise.columns:\n",
    "    gap_patio_dados = df_completos['gap_patio_horas'].dropna()\n",
    "    if len(gap_patio_dados) > 0 and gap_patio_dados.mean() > 8:\n",
    "        print(f\"   ‚ö†Ô∏è Gap P√°tio alto (m√©dia: {gap_patio_dados.mean():.1f}h)\")\n",
    "        print(f\"   üí° Otimizar processo interno de libera√ß√£o\")\n",
    "\n",
    "print(f\"\\n‚úÖ PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
    "print(f\"   1. Implementar follow-up autom√°tico para processos incompletos\")\n",
    "print(f\"   2. Definir SLAs para cada etapa do processo\")\n",
    "print(f\"   3. Criar alertas para gaps > 24h\")\n",
    "print(f\"   4. Analisar causas dos gaps mais longos\")\n",
    "print(f\"   5. Implementar dashboards em tempo real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVAR DADOS PROCESSADOS\n",
    "print(\"üíæ SALVANDO DADOS PROCESSADOS...\")\n",
    "\n",
    "# Salvar dataframe com an√°lises\n",
    "arquivo_saida = 'dados_gaps_terloc_processados.csv'\n",
    "df_analise.to_csv(arquivo_saida, index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úÖ Dados salvos em: {arquivo_saida}\")\n",
    "\n",
    "# Resumo das colunas criadas\n",
    "print(f\"\\nüìã COLUNAS ADICIONADAS NA AN√ÅLISE:\")\n",
    "colunas_novas = [\n",
    "    'timestamp_retorno_simbolico', 'timestamp_recebimento_nf', \n",
    "    'timestamp_ticket', 'timestamp_gate', 'timestamp_liberacao',\n",
    "    'gap_cliente_horas', 'gap_patio_horas', 'gap_ticket_gate_horas', \n",
    "    'gap_gate_liberacao_horas', 'processo_completo', 'campos_faltantes'\n",
    "]\n",
    "\n",
    "for col in colunas_novas:\n",
    "    if col in df_analise.columns:\n",
    "        print(f\"   ‚úÖ {col}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {col} (n√£o criada)\")\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISE CONCLU√çDA! Use este notebook para monitoramento cont√≠nuo dos gaps TERLOC.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
